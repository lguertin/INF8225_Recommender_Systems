{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#not to be run again, this was just to get the movie_title's from the movie_id's since we won't be using\n",
    "#the other details about movies\n",
    "###\n",
    "\n",
    "# f_r = \"./ml-100k/u.item\"\n",
    "# f_w = \"./ml-100k/u.item_modified\"\n",
    "# with open(f_r) as r_file, open(f_w, 'w') as w_file:\n",
    "#     data_r = r_file.read().splitlines()\n",
    "#     for l in data_r:\n",
    "#         line = l.split('|')\n",
    "#         w_file.write(line[0] + '|' + line[1] + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.optim import SGD, Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>18</td>\n",
       "      <td>134</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>18</td>\n",
       "      <td>137</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>18</td>\n",
       "      <td>142</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>18</td>\n",
       "      <td>143</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>18</td>\n",
       "      <td>153</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  movie_id  rating\n",
       "0           1         1    1.00\n",
       "1           1         2    0.50\n",
       "2           1         3    0.75\n",
       "3           1         4    0.50\n",
       "4           1         5    0.50\n",
       "...       ...       ...     ...\n",
       "1495       18       134    1.00\n",
       "1496       18       137    1.00\n",
       "1497       18       142    0.75\n",
       "1498       18       143    0.75\n",
       "1499       18       153    0.75\n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"user_id\", \"movie_id\", \"rating\"]\n",
    "#see http://files.grouplens.org/datasets/movielens/ml-100k-README.txt\n",
    "n_users, n_items, n_ratings = 943, 1682, 100000     #each user is unique and has rated at least 20 movies, and the movies have been rated by enough users  \n",
    "train_data = pd.read_csv(\"./ml-100k/u1.base\", sep='\\t', names=cols, usecols=cols).astype(int)\n",
    "test_data = pd.read_csv(\"./ml-100k/u1.test\", sep='\\t', names=cols, usecols=cols).astype(int)\n",
    "# train_data.head(2000)\n",
    "# test_data.head()\n",
    "\n",
    "train_data[[\"rating\"]] = preprocessing.MinMaxScaler().fit_transform(train_data[[\"rating\"]].values.astype(float))\n",
    "test_data[[\"rating\"]] = preprocessing.MinMaxScaler().fit_transform(test_data[[\"rating\"]].values.astype(float))\n",
    "\n",
    "train_data.head(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>18</td>\n",
       "      <td>134</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Citizen Kane (1941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>18</td>\n",
       "      <td>137</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Big Night (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>18</td>\n",
       "      <td>142</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Bedknobs and Broomsticks (1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>18</td>\n",
       "      <td>143</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Sound of Music, The (1965)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>18</td>\n",
       "      <td>153</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Fish Called Wanda, A (1988)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  movie_id  rating                      movie_title\n",
       "0           1         1    1.00                 Toy Story (1995)\n",
       "1           1         2    0.50                 GoldenEye (1995)\n",
       "2           1         3    0.75                Four Rooms (1995)\n",
       "3           1         4    0.50                Get Shorty (1995)\n",
       "4           1         5    0.50                   Copycat (1995)\n",
       "...       ...       ...     ...                              ...\n",
       "1495       18       134    1.00              Citizen Kane (1941)\n",
       "1496       18       137    1.00                 Big Night (1996)\n",
       "1497       18       142    0.75  Bedknobs and Broomsticks (1971)\n",
       "1498       18       143    0.75       Sound of Music, The (1965)\n",
       "1499       18       153    0.75      Fish Called Wanda, A (1988)\n",
       "\n",
       "[1500 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we didn't use the movie_titles in the end, because we didn't have time to develop an app for recommending items, but it would have been nice\n",
    "cols = [\"movie_id\", \"movie_title\"]\n",
    "movie_data = pd.read_csv(\"./ml-100k/u.item_modified\", sep='|', names=cols, usecols=cols, encoding='latin-1')\n",
    "# movie_data.head()\n",
    "train_data_movie = pd.merge(train_data, movie_data, how='left')\n",
    "train_data_movie.head(1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilities\n",
    "#function used to get the minibatches\n",
    "def iter_minibatches(train_data, batch_size, shuffle=True):\n",
    "    users, items, ratings = train_data[\"user_id\"], train_data[\"movie_id\"], train_data[\"rating\"]\n",
    "    if shuffle:\n",
    "        indices = np.arange(users.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for idx in range(0, users.shape[0] - batch_size + 1, batch_size):\n",
    "        slc = indices[idx:idx + batch_size] if shuffle else slice(idx, idx + batch_size)\n",
    "        yield users[slc], items[slc], ratings[slc]\n",
    "\n",
    "#function used to train the models\n",
    "def train(n_epochs, train_data, batch_size, optimizer, loss_func, model):\n",
    "    model.train()\n",
    "    avg_losses = []\n",
    "    for e in range(n_epochs):\n",
    "        losses = []\n",
    "        for users, items, ratings in iter_minibatches(train_data, batch_size):\n",
    "            users = Variable(torch.LongTensor(users.values)).cuda()\n",
    "            items = Variable(torch.LongTensor(items.values)).cuda()\n",
    "            ratings = Variable(torch.FloatTensor(ratings.values)).cuda()\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(users, items)\n",
    "            train_loss = loss_func(predictions, ratings)\n",
    "            losses.append(train_loss.item())\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        avg_loss = sum(losses)/len(losses)\n",
    "#         print(\"epoch\", e, \":\", avg_loss)\n",
    "        avg_losses.append(avg_loss)\n",
    "    state = model.state_dict()\n",
    "    return avg_losses, state\n",
    "\n",
    "#function used to evaluate the models\n",
    "def evaluate(model, test_data):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        users = Variable(torch.LongTensor(test_data[\"user_id\"].values)).cuda()\n",
    "        items = Variable(torch.LongTensor(test_data[\"movie_id\"].values)).cuda()\n",
    "        test_pred = model(users, items)\n",
    "#         print(test_pred.cpu().numpy())\n",
    "        return test_pred\n",
    "\n",
    "def show_plots(mf_data, dn_data, x_s, labels):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(x_s, mf_data, label = \"MF\")\n",
    "    plt.plot(x_s, dn_data, label = \"DN\")\n",
    "    plt.xlabel(labels[0])\n",
    "    plt.ylabel(labels[1])\n",
    "#     plt.xlim(0, mf_data[-1][0])\n",
    "    plt.title(labels[2])\n",
    "    plt.legend(loc = \"best\")\n",
    "    plt.show()\n",
    "    fig.savefig(\"./graphs/\" + labels[2] + '.png', format='png')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFacto(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.users_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.items_factors = nn.Embedding(n_items, n_factors)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        return (self.users_factors(user) * self.items_factors(item)).sum(1)\n",
    "            \n",
    "    def predict(self, user, item):\n",
    "        self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DN(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):  #n_factors is also hyperparam #see https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf\n",
    "        super().__init__()\n",
    "        self.users_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.items_factors = nn.Embedding(n_items, n_factors)\n",
    "        self.L1 = nn.Linear(n_factors*2, n_factors)\n",
    "        self.L2 = nn.Linear(n_factors, n_factors)\n",
    "        self.L3 = nn.Linear(n_factors, 1)\n",
    "        self.drop = nn.Dropout()\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        x = torch.cat([self.users_factors(user), self.items_factors(item)], dim=1)\n",
    "        x = F.relu(self.L1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.L2(x))\n",
    "        x = self.drop(x)\n",
    "        return self.L3(x)\n",
    "            \n",
    "    def predict(self, user, item):\n",
    "        self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 21.053969694519044\n",
      "epoch 1 : 20.831495652770997\n",
      "epoch 2 : 20.612967529296874\n",
      "epoch 3 : 20.398253506469725\n",
      "epoch 4 : 20.187297953796385\n",
      "epoch 5 : 19.979980278015137\n",
      "epoch 6 : 19.776206701660158\n",
      "epoch 7 : 19.575915104675293\n",
      "epoch 8 : 19.379024282836912\n",
      "epoch 9 : 19.18543723449707\n",
      "epoch 10 : 18.99507763519287\n",
      "epoch 11 : 18.807878257751465\n",
      "epoch 12 : 18.623762652587892\n",
      "epoch 13 : 18.442653874206542\n",
      "epoch 14 : 18.26449883880615\n",
      "epoch 15 : 18.089228463745116\n",
      "epoch 16 : 17.916752043151856\n",
      "epoch 17 : 17.74704100494385\n",
      "epoch 18 : 17.580003843688964\n",
      "epoch 19 : 17.415608694458008\n",
      "epoch 20 : 17.253770672607423\n",
      "epoch 21 : 17.09446026611328\n",
      "epoch 22 : 16.937606455993652\n",
      "epoch 23 : 16.783162030029295\n",
      "epoch 24 : 16.631065028381347\n",
      "epoch 25 : 16.481277262878418\n",
      "epoch 26 : 16.333761018371582\n",
      "epoch 27 : 16.188447265625\n",
      "epoch 28 : 16.045289070129396\n",
      "epoch 29 : 15.904266760253906\n",
      "epoch 30 : 15.765299015808106\n",
      "epoch 31 : 15.628388700866699\n",
      "epoch 32 : 15.493453430175782\n",
      "epoch 33 : 15.36046979522705\n",
      "epoch 34 : 15.229404730224608\n",
      "epoch 35 : 15.100209281921387\n",
      "epoch 36 : 14.972847778320313\n",
      "epoch 37 : 14.847283647155761\n",
      "epoch 38 : 14.72349469909668\n",
      "epoch 39 : 14.601436817932129\n",
      "epoch 40 : 14.48107592163086\n",
      "epoch 41 : 14.362370944213867\n",
      "epoch 42 : 14.245311617279052\n",
      "epoch 43 : 14.129833712768555\n",
      "epoch 44 : 14.015940653991699\n",
      "epoch 45 : 13.90358123474121\n",
      "epoch 46 : 13.792745635986329\n",
      "epoch 47 : 13.683383503723144\n",
      "epoch 48 : 13.575469116210938\n",
      "epoch 49 : 13.469000694274902\n",
      "[21.053969694519044, 20.831495652770997, 20.612967529296874, 20.398253506469725, 20.187297953796385, 19.979980278015137, 19.776206701660158, 19.575915104675293, 19.379024282836912, 19.18543723449707, 18.99507763519287, 18.807878257751465, 18.623762652587892, 18.442653874206542, 18.26449883880615, 18.089228463745116, 17.916752043151856, 17.74704100494385, 17.580003843688964, 17.415608694458008, 17.253770672607423, 17.09446026611328, 16.937606455993652, 16.783162030029295, 16.631065028381347, 16.481277262878418, 16.333761018371582, 16.188447265625, 16.045289070129396, 15.904266760253906, 15.765299015808106, 15.628388700866699, 15.493453430175782, 15.36046979522705, 15.229404730224608, 15.100209281921387, 14.972847778320313, 14.847283647155761, 14.72349469909668, 14.601436817932129, 14.48107592163086, 14.362370944213867, 14.245311617279052, 14.129833712768555, 14.015940653991699, 13.90358123474121, 13.792745635986329, 13.683383503723144, 13.575469116210938, 13.469000694274902]\n",
      "[-1.6934023   2.0440843  -1.1411767  ...  5.0115128  -0.14046848\n",
      "  2.3992274 ]\n",
      "--------------------------------------------------\n",
      "epoch 0 : 2.8572096797943116\n",
      "epoch 1 : 2.8558148509979246\n",
      "epoch 2 : 2.854420588302612\n",
      "epoch 3 : 2.8530272621154786\n",
      "epoch 4 : 2.8516348644256593\n",
      "epoch 5 : 2.8502433197021486\n",
      "epoch 6 : 2.848852854156494\n",
      "epoch 7 : 2.847463152694702\n",
      "epoch 8 : 2.8460742519378663\n",
      "epoch 9 : 2.8446859886169436\n",
      "epoch 10 : 2.8432985218048095\n",
      "epoch 11 : 2.8419118225097657\n",
      "epoch 12 : 2.84052610168457\n",
      "epoch 13 : 2.8391411884307862\n",
      "epoch 14 : 2.837757148742676\n",
      "epoch 15 : 2.8363737716674806\n",
      "epoch 16 : 2.8349911430358885\n",
      "epoch 17 : 2.8336093852996824\n",
      "epoch 18 : 2.8322284870147705\n",
      "epoch 19 : 2.8308484142303465\n",
      "epoch 20 : 2.8294691513061525\n",
      "epoch 21 : 2.828090596008301\n",
      "epoch 22 : 2.826712826538086\n",
      "epoch 23 : 2.8253357429504393\n",
      "epoch 24 : 2.8239593589782714\n",
      "epoch 25 : 2.8225839351654054\n",
      "epoch 26 : 2.8212092231750487\n",
      "epoch 27 : 2.819835481262207\n",
      "epoch 28 : 2.8184623798370363\n",
      "epoch 29 : 2.817089930343628\n",
      "epoch 30 : 2.815718367767334\n",
      "epoch 31 : 2.814347547149658\n",
      "epoch 32 : 2.8129775096893312\n",
      "epoch 33 : 2.811608352661133\n",
      "epoch 34 : 2.8102398609161376\n",
      "epoch 35 : 2.8088722328186035\n",
      "epoch 36 : 2.8075055122375487\n",
      "epoch 37 : 2.80613967628479\n",
      "epoch 38 : 2.8047745876312256\n",
      "epoch 39 : 2.8034103393554686\n",
      "epoch 40 : 2.8020471183776854\n",
      "epoch 41 : 2.800684548187256\n",
      "epoch 42 : 2.799322618484497\n",
      "epoch 43 : 2.7979613574981688\n",
      "epoch 44 : 2.796600854110718\n",
      "epoch 45 : 2.7952412548065184\n",
      "epoch 46 : 2.793882395553589\n",
      "epoch 47 : 2.7925243476867676\n",
      "epoch 48 : 2.7911672313690183\n",
      "epoch 49 : 2.7898108543395996\n",
      "[2.8572096797943116, 2.8558148509979246, 2.854420588302612, 2.8530272621154786, 2.8516348644256593, 2.8502433197021486, 2.848852854156494, 2.847463152694702, 2.8460742519378663, 2.8446859886169436, 2.8432985218048095, 2.8419118225097657, 2.84052610168457, 2.8391411884307862, 2.837757148742676, 2.8363737716674806, 2.8349911430358885, 2.8336093852996824, 2.8322284870147705, 2.8308484142303465, 2.8294691513061525, 2.828090596008301, 2.826712826538086, 2.8253357429504393, 2.8239593589782714, 2.8225839351654054, 2.8212092231750487, 2.819835481262207, 2.8184623798370363, 2.817089930343628, 2.815718367767334, 2.814347547149658, 2.8129775096893312, 2.811608352661133, 2.8102398609161376, 2.8088722328186035, 2.8075055122375487, 2.80613967628479, 2.8047745876312256, 2.8034103393554686, 2.8020471183776854, 2.800684548187256, 2.799322618484497, 2.7979613574981688, 2.796600854110718, 2.7952412548065184, 2.793882395553589, 2.7925243476867676, 2.7911672313690183, 2.7898108543395996]\n",
      "[-1.6608493   1.9878883  -1.1304116  ...  4.9673753  -0.13920489\n",
      "  2.3741174 ]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:432: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.2530048536300659\n",
      "epoch 1 : 0.11297468888759613\n",
      "epoch 2 : 0.09795149326324464\n",
      "epoch 3 : 0.09111199123859405\n",
      "epoch 4 : 0.08714410153627396\n",
      "epoch 5 : 0.08470295256376266\n",
      "epoch 6 : 0.08319654482007027\n",
      "epoch 7 : 0.08202576349973678\n",
      "epoch 8 : 0.08127522342801094\n",
      "epoch 9 : 0.08067617354393006\n",
      "epoch 10 : 0.08024288470149041\n",
      "epoch 11 : 0.07990696952342988\n",
      "epoch 12 : 0.07967012988328934\n",
      "epoch 13 : 0.07946035281419754\n",
      "epoch 14 : 0.07930365816950798\n",
      "epoch 15 : 0.07917409924864768\n",
      "epoch 16 : 0.07906756545305252\n",
      "epoch 17 : 0.07898206441402435\n",
      "epoch 18 : 0.0788928180873394\n",
      "epoch 19 : 0.07882969291210175\n",
      "epoch 20 : 0.0787651340007782\n",
      "epoch 21 : 0.07871293692588806\n",
      "epoch 22 : 0.07866089506745338\n",
      "epoch 23 : 0.0786322308421135\n",
      "epoch 24 : 0.07858890459537506\n",
      "epoch 25 : 0.07856076148748398\n",
      "epoch 26 : 0.07854051956534386\n",
      "epoch 27 : 0.07851333721280097\n",
      "epoch 28 : 0.07848939229846001\n",
      "epoch 29 : 0.07846649208068848\n",
      "epoch 30 : 0.07845228385925293\n",
      "epoch 31 : 0.07843584907054901\n",
      "epoch 32 : 0.0784158502817154\n",
      "epoch 33 : 0.07840169445872307\n",
      "epoch 34 : 0.07838580702543259\n",
      "epoch 35 : 0.07837612859606743\n",
      "epoch 36 : 0.07836786006093026\n",
      "epoch 37 : 0.07835216073393822\n",
      "epoch 38 : 0.0783512872517109\n",
      "epoch 39 : 0.07833959199786186\n",
      "epoch 40 : 0.07833352954983712\n",
      "epoch 41 : 0.07832397478818894\n",
      "epoch 42 : 0.0783195816040039\n",
      "epoch 43 : 0.07830895043611527\n",
      "epoch 44 : 0.07830623928308487\n",
      "epoch 45 : 0.07830212641954422\n",
      "epoch 46 : 0.07829375197887421\n",
      "epoch 47 : 0.07829214652776718\n",
      "epoch 48 : 0.07828237833976745\n",
      "epoch 49 : 0.07828125767707825\n",
      "[0.2530048536300659, 0.11297468888759613, 0.09795149326324464, 0.09111199123859405, 0.08714410153627396, 0.08470295256376266, 0.08319654482007027, 0.08202576349973678, 0.08127522342801094, 0.08067617354393006, 0.08024288470149041, 0.07990696952342988, 0.07967012988328934, 0.07946035281419754, 0.07930365816950798, 0.07917409924864768, 0.07906756545305252, 0.07898206441402435, 0.0788928180873394, 0.07882969291210175, 0.0787651340007782, 0.07871293692588806, 0.07866089506745338, 0.0786322308421135, 0.07858890459537506, 0.07856076148748398, 0.07854051956534386, 0.07851333721280097, 0.07848939229846001, 0.07846649208068848, 0.07845228385925293, 0.07843584907054901, 0.0784158502817154, 0.07840169445872307, 0.07838580702543259, 0.07837612859606743, 0.07836786006093026, 0.07835216073393822, 0.0783512872517109, 0.07833959199786186, 0.07833352954983712, 0.07832397478818894, 0.0783195816040039, 0.07830895043611527, 0.07830623928308487, 0.07830212641954422, 0.07829375197887421, 0.07829214652776718, 0.07828237833976745, 0.07828125767707825]\n",
      "[[0.6329603 ]\n",
      " [0.6345745 ]\n",
      " [0.6360592 ]\n",
      " ...\n",
      " [0.6333905 ]\n",
      " [0.6314982 ]\n",
      " [0.63133067]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.2303202168226242\n",
      "epoch 1 : 0.22545911169052124\n",
      "epoch 2 : 0.22425504932403564\n",
      "epoch 3 : 0.22343055787086485\n",
      "epoch 4 : 0.22296357233524322\n",
      "epoch 5 : 0.2228001259326935\n",
      "epoch 6 : 0.2227823938846588\n",
      "epoch 7 : 0.2227570528268814\n",
      "epoch 8 : 0.22274400057792665\n",
      "epoch 9 : 0.22272556743621827\n",
      "epoch 10 : 0.2227049681186676\n",
      "epoch 11 : 0.2226871584892273\n",
      "epoch 12 : 0.22266898646354674\n",
      "epoch 13 : 0.22265367336273192\n",
      "epoch 14 : 0.2226410178422928\n",
      "epoch 15 : 0.22263435277938842\n",
      "epoch 16 : 0.22263045899868011\n",
      "epoch 17 : 0.22262187225818633\n",
      "epoch 18 : 0.2226193661928177\n",
      "epoch 19 : 0.22261296269893646\n",
      "epoch 20 : 0.22260550467967988\n",
      "epoch 21 : 0.22260312936306\n",
      "epoch 22 : 0.22260487508773805\n",
      "epoch 23 : 0.2226054583311081\n",
      "epoch 24 : 0.2226034341096878\n",
      "epoch 25 : 0.22260281562805176\n",
      "epoch 26 : 0.2226038860797882\n",
      "epoch 27 : 0.22260358734130858\n",
      "epoch 28 : 0.22260443305969238\n",
      "epoch 29 : 0.22260412282943726\n",
      "epoch 30 : 0.22260257465839386\n",
      "epoch 31 : 0.22260320706367492\n",
      "epoch 32 : 0.2226027338027954\n",
      "epoch 33 : 0.22260438199043273\n",
      "epoch 34 : 0.22260439212322236\n",
      "epoch 35 : 0.22260334692001343\n",
      "epoch 36 : 0.22260449407100677\n",
      "epoch 37 : 0.2226024043083191\n",
      "epoch 38 : 0.22260251572132111\n",
      "epoch 39 : 0.222604656291008\n",
      "epoch 40 : 0.22260466408729554\n",
      "epoch 41 : 0.22260186896324158\n",
      "epoch 42 : 0.22260631964206695\n",
      "epoch 43 : 0.2226023963689804\n",
      "epoch 44 : 0.2226031137228012\n",
      "epoch 45 : 0.222603448677063\n",
      "epoch 46 : 0.22260218274593352\n",
      "epoch 47 : 0.22260377309322357\n",
      "epoch 48 : 0.2226033665418625\n",
      "epoch 49 : 0.22260462419986723\n",
      "[0.2303202168226242, 0.22545911169052124, 0.22425504932403564, 0.22343055787086485, 0.22296357233524322, 0.2228001259326935, 0.2227823938846588, 0.2227570528268814, 0.22274400057792665, 0.22272556743621827, 0.2227049681186676, 0.2226871584892273, 0.22266898646354674, 0.22265367336273192, 0.2226410178422928, 0.22263435277938842, 0.22263045899868011, 0.22262187225818633, 0.2226193661928177, 0.22261296269893646, 0.22260550467967988, 0.22260312936306, 0.22260487508773805, 0.2226054583311081, 0.2226034341096878, 0.22260281562805176, 0.2226038860797882, 0.22260358734130858, 0.22260443305969238, 0.22260412282943726, 0.22260257465839386, 0.22260320706367492, 0.2226027338027954, 0.22260438199043273, 0.22260439212322236, 0.22260334692001343, 0.22260449407100677, 0.2226024043083191, 0.22260251572132111, 0.222604656291008, 0.22260466408729554, 0.22260186896324158, 0.22260631964206695, 0.2226023963689804, 0.2226031137228012, 0.222603448677063, 0.22260218274593352, 0.22260377309322357, 0.2226033665418625, 0.22260462419986723]\n",
      "[[0.74977946]\n",
      " [0.74975556]\n",
      " [0.74977547]\n",
      " ...\n",
      " [0.7497774 ]\n",
      " [0.7497634 ]\n",
      " [0.74976313]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_factors = 20\n",
    "batch_size = 128\n",
    "\n",
    "n_epochs = 50\n",
    "avg_losses = {}\n",
    "states = {}\n",
    "metrics = {}\n",
    "models = {\"MatrixFacto\": MatrixFacto(n_users, n_items, n_factors), \"DN\": DN(n_users, n_items, n_factors)}\n",
    "losses = {\"MSELoss\": nn.MSELoss(), \"L1Loss\": nn.L1Loss()}\n",
    "\n",
    "for model_ in models:\n",
    "    for l in losses:\n",
    "        model = models[model_]\n",
    "        optimizer = SGD(model.parameters(), lr=0.001)\n",
    "        model.cuda()\n",
    "        avg_ = []\n",
    "        n_iters = 10\n",
    "        loss_func = losses[l]\n",
    "        for i in range(n_iters):\n",
    "            avg_losses_i, state = train(n_epochs, train_data, batch_size, optimizer, loss_func, model)\n",
    "            avg_.append(avg_losses_i)\n",
    "        avg_losses_ = [None] * n_epochs\n",
    "        for i in range(n_epochs):\n",
    "            avg = 0\n",
    "            for j in range(n_iters):\n",
    "                avg += avg_[j][i]\n",
    "            avg_losses_[i] = avg / n_iters\n",
    "#         print(avg_losses_)            \n",
    "        avg_losses[model_ + \"_SGD_\" + l] = avg_losses_\n",
    "        states[model_ + \"_SGD_\" + l] = state\n",
    "        test_pred = evaluate(model, test_data)\n",
    "        metrics[model_ + \"_SGD_\" + l] = [mean_squared_error(test_pred.cpu().numpy(), test_data[\"rating\"].values), \n",
    "                   mean_absolute_error(test_pred.cpu().numpy(), test_data[\"rating\"].values)]\n",
    "        print('-'*50)\n",
    "    \n",
    "\n",
    "# torch.save(states[-1], \"./model_state_preprocessed_Adam_MSE.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MatrixFacto_SGD_MSELoss': [21.053969694519044, 20.831495652770997, 20.612967529296874, 20.398253506469725, 20.187297953796385, 19.979980278015137, 19.776206701660158, 19.575915104675293, 19.379024282836912, 19.18543723449707, 18.99507763519287, 18.807878257751465, 18.623762652587892, 18.442653874206542, 18.26449883880615, 18.089228463745116, 17.916752043151856, 17.74704100494385, 17.580003843688964, 17.415608694458008, 17.253770672607423, 17.09446026611328, 16.937606455993652, 16.783162030029295, 16.631065028381347, 16.481277262878418, 16.333761018371582, 16.188447265625, 16.045289070129396, 15.904266760253906, 15.765299015808106, 15.628388700866699, 15.493453430175782, 15.36046979522705, 15.229404730224608, 15.100209281921387, 14.972847778320313, 14.847283647155761, 14.72349469909668, 14.601436817932129, 14.48107592163086, 14.362370944213867, 14.245311617279052, 14.129833712768555, 14.015940653991699, 13.90358123474121, 13.792745635986329, 13.683383503723144, 13.575469116210938, 13.469000694274902], 'MatrixFacto_SGD_L1Loss': [2.8572096797943116, 2.8558148509979246, 2.854420588302612, 2.8530272621154786, 2.8516348644256593, 2.8502433197021486, 2.848852854156494, 2.847463152694702, 2.8460742519378663, 2.8446859886169436, 2.8432985218048095, 2.8419118225097657, 2.84052610168457, 2.8391411884307862, 2.837757148742676, 2.8363737716674806, 2.8349911430358885, 2.8336093852996824, 2.8322284870147705, 2.8308484142303465, 2.8294691513061525, 2.828090596008301, 2.826712826538086, 2.8253357429504393, 2.8239593589782714, 2.8225839351654054, 2.8212092231750487, 2.819835481262207, 2.8184623798370363, 2.817089930343628, 2.815718367767334, 2.814347547149658, 2.8129775096893312, 2.811608352661133, 2.8102398609161376, 2.8088722328186035, 2.8075055122375487, 2.80613967628479, 2.8047745876312256, 2.8034103393554686, 2.8020471183776854, 2.800684548187256, 2.799322618484497, 2.7979613574981688, 2.796600854110718, 2.7952412548065184, 2.793882395553589, 2.7925243476867676, 2.7911672313690183, 2.7898108543395996], 'DN_SGD_MSELoss': [0.2530048536300659, 0.11297468888759613, 0.09795149326324464, 0.09111199123859405, 0.08714410153627396, 0.08470295256376266, 0.08319654482007027, 0.08202576349973678, 0.08127522342801094, 0.08067617354393006, 0.08024288470149041, 0.07990696952342988, 0.07967012988328934, 0.07946035281419754, 0.07930365816950798, 0.07917409924864768, 0.07906756545305252, 0.07898206441402435, 0.0788928180873394, 0.07882969291210175, 0.0787651340007782, 0.07871293692588806, 0.07866089506745338, 0.0786322308421135, 0.07858890459537506, 0.07856076148748398, 0.07854051956534386, 0.07851333721280097, 0.07848939229846001, 0.07846649208068848, 0.07845228385925293, 0.07843584907054901, 0.0784158502817154, 0.07840169445872307, 0.07838580702543259, 0.07837612859606743, 0.07836786006093026, 0.07835216073393822, 0.0783512872517109, 0.07833959199786186, 0.07833352954983712, 0.07832397478818894, 0.0783195816040039, 0.07830895043611527, 0.07830623928308487, 0.07830212641954422, 0.07829375197887421, 0.07829214652776718, 0.07828237833976745, 0.07828125767707825], 'DN_SGD_L1Loss': [0.2303202168226242, 0.22545911169052124, 0.22425504932403564, 0.22343055787086485, 0.22296357233524322, 0.2228001259326935, 0.2227823938846588, 0.2227570528268814, 0.22274400057792665, 0.22272556743621827, 0.2227049681186676, 0.2226871584892273, 0.22266898646354674, 0.22265367336273192, 0.2226410178422928, 0.22263435277938842, 0.22263045899868011, 0.22262187225818633, 0.2226193661928177, 0.22261296269893646, 0.22260550467967988, 0.22260312936306, 0.22260487508773805, 0.2226054583311081, 0.2226034341096878, 0.22260281562805176, 0.2226038860797882, 0.22260358734130858, 0.22260443305969238, 0.22260412282943726, 0.22260257465839386, 0.22260320706367492, 0.2226027338027954, 0.22260438199043273, 0.22260439212322236, 0.22260334692001343, 0.22260449407100677, 0.2226024043083191, 0.22260251572132111, 0.222604656291008, 0.22260466408729554, 0.22260186896324158, 0.22260631964206695, 0.2226023963689804, 0.2226031137228012, 0.222603448677063, 0.22260218274593352, 0.22260377309322357, 0.2226033665418625, 0.22260462419986723]}\n",
      "{'MatrixFacto_SGD_MSELoss': [15.379793706829794, 3.07764855003953], 'MatrixFacto_SGD_L1Loss': [14.911725127225354, 3.0269195351488887], 'DN_SGD_MSELoss': [0.08317615482297047, 0.24198760321438312], 'DN_SGD_L1Loss': [0.09659175085210768, 0.22747792307436465]}\n"
     ]
    }
   ],
   "source": [
    "print(avg_losses)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = len(avg_losses[\"MatrixFacto_SGD_MSELoss\"])\n",
    "x_s = [i for i in range(n_epochs)]\n",
    "show_plots(avg_losses[\"MatrixFacto_SGD_MSELoss\"], avg_losses[\"DN_SGD_MSELoss\"], x_s, [\"epoch\", \"perte moyenne\", \"La perte moyenne selon l'epoch (SGD, MSELoss)\"])\n",
    "show_plots(avg_losses[\"MatrixFacto_SGD_L1Loss\"], avg_losses[\"DN_SGD_L1Loss\"], x_s, [\"epoch\", \"perte moyenne\", \"La perte moyenne selon l'epoch (SGD, L1Loss)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 18.33378876953125\n",
      "epoch 1 : 14.413975028991699\n",
      "epoch 2 : 11.418426676177978\n",
      "epoch 3 : 9.10276570892334\n",
      "epoch 4 : 7.290267041015625\n",
      "epoch 5 : 5.859876419830322\n",
      "epoch 6 : 4.72393437461853\n",
      "epoch 7 : 3.8192803817749024\n",
      "epoch 8 : 3.098384078979492\n",
      "epoch 9 : 2.5243771909713746\n",
      "epoch 10 : 2.068568662071228\n",
      "epoch 11 : 1.7063698741912843\n",
      "epoch 12 : 1.4185018747329712\n",
      "epoch 13 : 1.1888890617370604\n",
      "epoch 14 : 1.0049608078956604\n",
      "epoch 15 : 0.855635751914978\n",
      "epoch 16 : 0.7316529635429382\n",
      "epoch 17 : 0.6258459560394287\n",
      "epoch 18 : 0.5327112869262696\n",
      "epoch 19 : 0.4489323290348053\n",
      "epoch 20 : 0.373633712387085\n",
      "epoch 21 : 0.30762681739330294\n",
      "epoch 22 : 0.2518017887830734\n",
      "epoch 23 : 0.20628718775510788\n",
      "epoch 24 : 0.16994985133409501\n",
      "epoch 25 : 0.14160473284721375\n",
      "epoch 26 : 0.11966110991239548\n",
      "epoch 27 : 0.10267960604429245\n",
      "epoch 28 : 0.08954281192421913\n",
      "epoch 29 : 0.07943375690579414\n",
      "epoch 30 : 0.07159591835141182\n",
      "epoch 31 : 0.0655304567694664\n",
      "epoch 32 : 0.06071231521964073\n",
      "epoch 33 : 0.056941547083854675\n",
      "epoch 34 : 0.05392361536026001\n",
      "epoch 35 : 0.051528688129782674\n",
      "epoch 36 : 0.04953047325015068\n",
      "epoch 37 : 0.04792481352686882\n",
      "epoch 38 : 0.046614990019798276\n",
      "epoch 39 : 0.04542190981805325\n",
      "epoch 40 : 0.04451902270913124\n",
      "epoch 41 : 0.043625860816240314\n",
      "epoch 42 : 0.042904652950167654\n",
      "epoch 43 : 0.04225571100413799\n",
      "epoch 44 : 0.04167609985172749\n",
      "epoch 45 : 0.041129642948508266\n",
      "epoch 46 : 0.040664142060279844\n",
      "epoch 47 : 0.04018661751151085\n",
      "epoch 48 : 0.03976848337650299\n",
      "epoch 49 : 0.03935331064462662\n",
      "[18.33378876953125, 14.413975028991699, 11.418426676177978, 9.10276570892334, 7.290267041015625, 5.859876419830322, 4.72393437461853, 3.8192803817749024, 3.098384078979492, 2.5243771909713746, 2.068568662071228, 1.7063698741912843, 1.4185018747329712, 1.1888890617370604, 1.0049608078956604, 0.855635751914978, 0.7316529635429382, 0.6258459560394287, 0.5327112869262696, 0.4489323290348053, 0.373633712387085, 0.30762681739330294, 0.2518017887830734, 0.20628718775510788, 0.16994985133409501, 0.14160473284721375, 0.11966110991239548, 0.10267960604429245, 0.08954281192421913, 0.07943375690579414, 0.07159591835141182, 0.0655304567694664, 0.06071231521964073, 0.056941547083854675, 0.05392361536026001, 0.051528688129782674, 0.04953047325015068, 0.04792481352686882, 0.046614990019798276, 0.04542190981805325, 0.04451902270913124, 0.043625860816240314, 0.042904652950167654, 0.04225571100413799, 0.04167609985172749, 0.041129642948508266, 0.040664142060279844, 0.04018661751151085, 0.03976848337650299, 0.03935331064462662]\n",
      "[-0.08360636  0.61325836  0.9690418  ...  0.13754791  0.8090233\n",
      "  0.8526475 ]\n",
      "--------------------------------------------------\n",
      "epoch 0 : 0.15084761537313462\n",
      "epoch 1 : 0.14923822829723357\n",
      "epoch 2 : 0.14821221816539765\n",
      "epoch 3 : 0.14713194072246552\n",
      "epoch 4 : 0.1464334566116333\n",
      "epoch 5 : 0.14541075843572618\n",
      "epoch 6 : 0.14497809648513793\n",
      "epoch 7 : 0.14406296743154526\n",
      "epoch 8 : 0.1435990805506706\n",
      "epoch 9 : 0.14309608079195021\n",
      "epoch 10 : 0.1423687681078911\n",
      "epoch 11 : 0.14180302304029466\n",
      "epoch 12 : 0.14146907464265823\n",
      "epoch 13 : 0.1410478524208069\n",
      "epoch 14 : 0.1404480157494545\n",
      "epoch 15 : 0.14012623373270036\n",
      "epoch 16 : 0.13963462796211243\n",
      "epoch 17 : 0.13914298958778382\n",
      "epoch 18 : 0.13876613104343413\n",
      "epoch 19 : 0.13835118861198425\n",
      "epoch 20 : 0.13794994683265685\n",
      "epoch 21 : 0.13761535456180574\n",
      "epoch 22 : 0.1372982729434967\n",
      "epoch 23 : 0.13683667041063308\n",
      "epoch 24 : 0.13655232145786286\n",
      "epoch 25 : 0.13624299120903016\n",
      "epoch 26 : 0.13591186213493348\n",
      "epoch 27 : 0.1355366259932518\n",
      "epoch 28 : 0.13526747218370438\n",
      "epoch 29 : 0.13477823553085327\n",
      "epoch 30 : 0.13465653318166732\n",
      "epoch 31 : 0.13422652677297592\n",
      "epoch 32 : 0.13404802607297897\n",
      "epoch 33 : 0.13376822682619094\n",
      "epoch 34 : 0.13335618510246278\n",
      "epoch 35 : 0.13313256593942643\n",
      "epoch 36 : 0.13287812613248826\n",
      "epoch 37 : 0.1325015909433365\n",
      "epoch 38 : 0.13234151273965836\n",
      "epoch 39 : 0.1319497196316719\n",
      "epoch 40 : 0.13174320133924483\n",
      "epoch 41 : 0.13145715516805648\n",
      "epoch 42 : 0.13115234255790711\n",
      "epoch 43 : 0.1309446224808693\n",
      "epoch 44 : 0.13076651386022567\n",
      "epoch 45 : 0.13041853123903274\n",
      "epoch 46 : 0.1301860869884491\n",
      "epoch 47 : 0.1299389298915863\n",
      "epoch 48 : 0.12967475571632386\n",
      "epoch 49 : 0.1294838932991028\n",
      "[0.15084761537313462, 0.14923822829723357, 0.14821221816539765, 0.14713194072246552, 0.1464334566116333, 0.14541075843572618, 0.14497809648513793, 0.14406296743154526, 0.1435990805506706, 0.14309608079195021, 0.1423687681078911, 0.14180302304029466, 0.14146907464265823, 0.1410478524208069, 0.1404480157494545, 0.14012623373270036, 0.13963462796211243, 0.13914298958778382, 0.13876613104343413, 0.13835118861198425, 0.13794994683265685, 0.13761535456180574, 0.1372982729434967, 0.13683667041063308, 0.13655232145786286, 0.13624299120903016, 0.13591186213493348, 0.1355366259932518, 0.13526747218370438, 0.13477823553085327, 0.13465653318166732, 0.13422652677297592, 0.13404802607297897, 0.13376822682619094, 0.13335618510246278, 0.13313256593942643, 0.13287812613248826, 0.1325015909433365, 0.13234151273965836, 0.1319497196316719, 0.13174320133924483, 0.13145715516805648, 0.13115234255790711, 0.1309446224808693, 0.13076651386022567, 0.13041853123903274, 0.1301860869884491, 0.1299389298915863, 0.12967475571632386, 0.1294838932991028]\n",
      "[-0.27897358  0.56601936  0.9690188  ...  0.2486527   1.1219966\n",
      "  0.4838339 ]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:432: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.12279825830459595\n",
      "epoch 1 : 0.08564505515098572\n",
      "epoch 2 : 0.08034111090898514\n",
      "epoch 3 : 0.07871074202060699\n",
      "epoch 4 : 0.07831434687972069\n",
      "epoch 5 : 0.07825675708651543\n",
      "epoch 6 : 0.07823144624829292\n",
      "epoch 7 : 0.07824067962765693\n",
      "epoch 8 : 0.07823040981292724\n",
      "epoch 9 : 0.078240814858675\n",
      "epoch 10 : 0.07822055807709694\n",
      "epoch 11 : 0.07821523087024689\n",
      "epoch 12 : 0.07820340669751168\n",
      "epoch 13 : 0.07822275068163871\n",
      "epoch 14 : 0.07821230232119561\n",
      "epoch 15 : 0.07821751529574394\n",
      "epoch 16 : 0.07822104944586754\n",
      "epoch 17 : 0.07821018629074096\n",
      "epoch 18 : 0.07821514053940773\n",
      "epoch 19 : 0.07821438885331154\n",
      "epoch 20 : 0.07820717009305954\n",
      "epoch 21 : 0.07821165447831153\n",
      "epoch 22 : 0.07821562950015068\n",
      "epoch 23 : 0.07821739233732224\n",
      "epoch 24 : 0.07819482551217079\n",
      "epoch 25 : 0.07821892893314361\n",
      "epoch 26 : 0.07821055293679237\n",
      "epoch 27 : 0.07821355277299881\n",
      "epoch 28 : 0.07821311166882515\n",
      "epoch 29 : 0.07821027456521988\n",
      "epoch 30 : 0.0782127207159996\n",
      "epoch 31 : 0.0782102813065052\n",
      "epoch 32 : 0.0782133539736271\n",
      "epoch 33 : 0.07821360504627228\n",
      "epoch 34 : 0.07820755386948586\n",
      "epoch 35 : 0.07821190978884697\n",
      "epoch 36 : 0.07821816404461861\n",
      "epoch 37 : 0.0782095521748066\n",
      "epoch 38 : 0.0782089751780033\n",
      "epoch 39 : 0.07820830301046372\n",
      "epoch 40 : 0.07821274411082267\n",
      "epoch 41 : 0.07821431694030762\n",
      "epoch 42 : 0.07820971868038178\n",
      "epoch 43 : 0.07821026002168656\n",
      "epoch 44 : 0.07821290121078492\n",
      "epoch 45 : 0.07821481345891952\n",
      "epoch 46 : 0.07820134246945382\n",
      "epoch 47 : 0.07821177031397819\n",
      "epoch 48 : 0.07821490562558174\n",
      "epoch 49 : 0.07820957511663437\n",
      "[0.12279825830459595, 0.08564505515098572, 0.08034111090898514, 0.07871074202060699, 0.07831434687972069, 0.07825675708651543, 0.07823144624829292, 0.07824067962765693, 0.07823040981292724, 0.078240814858675, 0.07822055807709694, 0.07821523087024689, 0.07820340669751168, 0.07822275068163871, 0.07821230232119561, 0.07821751529574394, 0.07822104944586754, 0.07821018629074096, 0.07821514053940773, 0.07821438885331154, 0.07820717009305954, 0.07821165447831153, 0.07821562950015068, 0.07821739233732224, 0.07819482551217079, 0.07821892893314361, 0.07821055293679237, 0.07821355277299881, 0.07821311166882515, 0.07821027456521988, 0.0782127207159996, 0.0782102813065052, 0.0782133539736271, 0.07821360504627228, 0.07820755386948586, 0.07821190978884697, 0.07821816404461861, 0.0782095521748066, 0.0782089751780033, 0.07820830301046372, 0.07821274411082267, 0.07821431694030762, 0.07820971868038178, 0.07821026002168656, 0.07821290121078492, 0.07821481345891952, 0.07820134246945382, 0.07821177031397819, 0.07821490562558174, 0.07820957511663437]\n",
      "[[0.6314089]\n",
      " [0.6314089]\n",
      " [0.6314089]\n",
      " ...\n",
      " [0.6314089]\n",
      " [0.6314089]\n",
      " [0.6314089]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.22385512256622314\n",
      "epoch 1 : 0.22261551458835602\n",
      "epoch 2 : 0.2226037743330002\n",
      "epoch 3 : 0.22261560711860656\n",
      "epoch 4 : 0.22260608689785003\n",
      "epoch 5 : 0.2226130387544632\n",
      "epoch 6 : 0.22261042404174805\n",
      "epoch 7 : 0.2226105916261673\n",
      "epoch 8 : 0.22261125226020814\n",
      "epoch 9 : 0.22260407514572145\n",
      "epoch 10 : 0.22260459923744202\n",
      "epoch 11 : 0.22261612718105317\n",
      "epoch 12 : 0.2226061758041382\n",
      "epoch 13 : 0.22260597236156462\n",
      "epoch 14 : 0.22261041631698608\n",
      "epoch 15 : 0.22260980699062347\n",
      "epoch 16 : 0.2226150236606598\n",
      "epoch 17 : 0.22260272357463837\n",
      "epoch 18 : 0.22260770144462586\n",
      "epoch 19 : 0.22260847120285035\n",
      "epoch 20 : 0.2226108144044876\n",
      "epoch 21 : 0.22261198077201844\n",
      "epoch 22 : 0.22261484532356263\n",
      "epoch 23 : 0.22260990130901337\n",
      "epoch 24 : 0.22260174441337585\n",
      "epoch 25 : 0.22260636937618256\n",
      "epoch 26 : 0.22261292955875397\n",
      "epoch 27 : 0.22259869611263275\n",
      "epoch 28 : 0.22261390337944031\n",
      "epoch 29 : 0.22261042187213897\n",
      "epoch 30 : 0.22260508949756622\n",
      "epoch 31 : 0.22261437945365906\n",
      "epoch 32 : 0.2226087951183319\n",
      "epoch 33 : 0.222614750623703\n",
      "epoch 34 : 0.22261286256313323\n",
      "epoch 35 : 0.22261211898326874\n",
      "epoch 36 : 0.22260393879413604\n",
      "epoch 37 : 0.2226060614824295\n",
      "epoch 38 : 0.22261173040866852\n",
      "epoch 39 : 0.22260979251861573\n",
      "epoch 40 : 0.22259949045181274\n",
      "epoch 41 : 0.2226040887117386\n",
      "epoch 42 : 0.22260211789608\n",
      "epoch 43 : 0.22260321989059448\n",
      "epoch 44 : 0.22262220017910003\n",
      "epoch 45 : 0.22261444697380067\n",
      "epoch 46 : 0.22261092658042908\n",
      "epoch 47 : 0.22260414242744445\n",
      "epoch 48 : 0.22260652565956116\n",
      "epoch 49 : 0.22259864790439607\n",
      "[0.22385512256622314, 0.22261551458835602, 0.2226037743330002, 0.22261560711860656, 0.22260608689785003, 0.2226130387544632, 0.22261042404174805, 0.2226105916261673, 0.22261125226020814, 0.22260407514572145, 0.22260459923744202, 0.22261612718105317, 0.2226061758041382, 0.22260597236156462, 0.22261041631698608, 0.22260980699062347, 0.2226150236606598, 0.22260272357463837, 0.22260770144462586, 0.22260847120285035, 0.2226108144044876, 0.22261198077201844, 0.22261484532356263, 0.22260990130901337, 0.22260174441337585, 0.22260636937618256, 0.22261292955875397, 0.22259869611263275, 0.22261390337944031, 0.22261042187213897, 0.22260508949756622, 0.22261437945365906, 0.2226087951183319, 0.222614750623703, 0.22261286256313323, 0.22261211898326874, 0.22260393879413604, 0.2226060614824295, 0.22261173040866852, 0.22260979251861573, 0.22259949045181274, 0.2226040887117386, 0.22260211789608, 0.22260321989059448, 0.22262220017910003, 0.22261444697380067, 0.22261092658042908, 0.22260414242744445, 0.22260652565956116, 0.22259864790439607]\n",
      "[[0.7501432]\n",
      " [0.7501432]\n",
      " [0.7501432]\n",
      " ...\n",
      " [0.7501432]\n",
      " [0.7501432]\n",
      " [0.7501432]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "n_factors = 20\n",
    "batch_size = 128\n",
    "\n",
    "n_epochs = 50\n",
    "avg_losses_adam = {}\n",
    "states_adam = {}\n",
    "metrics_adam = {}\n",
    "models = {\"MatrixFacto\": MatrixFacto(n_users, n_items, n_factors), \"DN\": DN(n_users, n_items, n_factors)}\n",
    "losses = {\"MSELoss\": nn.MSELoss(), \"L1Loss\": nn.L1Loss()}\n",
    "\n",
    "for model_ in models:\n",
    "    for l in losses:\n",
    "        model = models[model_]\n",
    "        optimizer = Adam(model.parameters(), lr=0.001)\n",
    "        model.cuda()\n",
    "        avg_ = []\n",
    "        n_iters = 10\n",
    "        loss_func = losses[l]\n",
    "        for i in range(n_iters):\n",
    "            avg_losses_i, state = train(n_epochs, train_data, batch_size, optimizer, loss_func, model)\n",
    "            avg_.append(avg_losses_i)\n",
    "        avg_losses_ = [None] * n_epochs\n",
    "        for i in range(n_epochs):\n",
    "            avg = 0\n",
    "            for j in range(n_iters):\n",
    "                avg += avg_[j][i]\n",
    "            avg_losses_[i] = avg / n_iters\n",
    "#         print(avg_losses_)            \n",
    "        avg_losses_adam[model_ + \"_Adam_\" + l] = avg_losses_\n",
    "        states_adam[model_ + \"_Adam_\" + l] = state\n",
    "        test_pred = evaluate(model, test_data)\n",
    "        metrics_adam[model_ + \"_Adam_\" + l] = [mean_squared_error(test_pred.cpu().numpy(), test_data[\"rating\"].values), \n",
    "                   mean_absolute_error(test_pred.cpu().numpy(), test_data[\"rating\"].values)]\n",
    "        print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MatrixFacto_Adam_MSELoss': [18.33378876953125, 14.413975028991699, 11.418426676177978, 9.10276570892334, 7.290267041015625, 5.859876419830322, 4.72393437461853, 3.8192803817749024, 3.098384078979492, 2.5243771909713746, 2.068568662071228, 1.7063698741912843, 1.4185018747329712, 1.1888890617370604, 1.0049608078956604, 0.855635751914978, 0.7316529635429382, 0.6258459560394287, 0.5327112869262696, 0.4489323290348053, 0.373633712387085, 0.30762681739330294, 0.2518017887830734, 0.20628718775510788, 0.16994985133409501, 0.14160473284721375, 0.11966110991239548, 0.10267960604429245, 0.08954281192421913, 0.07943375690579414, 0.07159591835141182, 0.0655304567694664, 0.06071231521964073, 0.056941547083854675, 0.05392361536026001, 0.051528688129782674, 0.04953047325015068, 0.04792481352686882, 0.046614990019798276, 0.04542190981805325, 0.04451902270913124, 0.043625860816240314, 0.042904652950167654, 0.04225571100413799, 0.04167609985172749, 0.041129642948508266, 0.040664142060279844, 0.04018661751151085, 0.03976848337650299, 0.03935331064462662], 'MatrixFacto_Adam_L1Loss': [0.15084761537313462, 0.14923822829723357, 0.14821221816539765, 0.14713194072246552, 0.1464334566116333, 0.14541075843572618, 0.14497809648513793, 0.14406296743154526, 0.1435990805506706, 0.14309608079195021, 0.1423687681078911, 0.14180302304029466, 0.14146907464265823, 0.1410478524208069, 0.1404480157494545, 0.14012623373270036, 0.13963462796211243, 0.13914298958778382, 0.13876613104343413, 0.13835118861198425, 0.13794994683265685, 0.13761535456180574, 0.1372982729434967, 0.13683667041063308, 0.13655232145786286, 0.13624299120903016, 0.13591186213493348, 0.1355366259932518, 0.13526747218370438, 0.13477823553085327, 0.13465653318166732, 0.13422652677297592, 0.13404802607297897, 0.13376822682619094, 0.13335618510246278, 0.13313256593942643, 0.13287812613248826, 0.1325015909433365, 0.13234151273965836, 0.1319497196316719, 0.13174320133924483, 0.13145715516805648, 0.13115234255790711, 0.1309446224808693, 0.13076651386022567, 0.13041853123903274, 0.1301860869884491, 0.1299389298915863, 0.12967475571632386, 0.1294838932991028], 'DN_Adam_MSELoss': [0.12279825830459595, 0.08564505515098572, 0.08034111090898514, 0.07871074202060699, 0.07831434687972069, 0.07825675708651543, 0.07823144624829292, 0.07824067962765693, 0.07823040981292724, 0.078240814858675, 0.07822055807709694, 0.07821523087024689, 0.07820340669751168, 0.07822275068163871, 0.07821230232119561, 0.07821751529574394, 0.07822104944586754, 0.07821018629074096, 0.07821514053940773, 0.07821438885331154, 0.07820717009305954, 0.07821165447831153, 0.07821562950015068, 0.07821739233732224, 0.07819482551217079, 0.07821892893314361, 0.07821055293679237, 0.07821355277299881, 0.07821311166882515, 0.07821027456521988, 0.0782127207159996, 0.0782102813065052, 0.0782133539736271, 0.07821360504627228, 0.07820755386948586, 0.07821190978884697, 0.07821816404461861, 0.0782095521748066, 0.0782089751780033, 0.07820830301046372, 0.07821274411082267, 0.07821431694030762, 0.07820971868038178, 0.07821026002168656, 0.07821290121078492, 0.07821481345891952, 0.07820134246945382, 0.07821177031397819, 0.07821490562558174, 0.07820957511663437], 'DN_Adam_L1Loss': [0.22385512256622314, 0.22261551458835602, 0.2226037743330002, 0.22261560711860656, 0.22260608689785003, 0.2226130387544632, 0.22261042404174805, 0.2226105916261673, 0.22261125226020814, 0.22260407514572145, 0.22260459923744202, 0.22261612718105317, 0.2226061758041382, 0.22260597236156462, 0.22261041631698608, 0.22260980699062347, 0.2226150236606598, 0.22260272357463837, 0.22260770144462586, 0.22260847120285035, 0.2226108144044876, 0.22261198077201844, 0.22261484532356263, 0.22260990130901337, 0.22260174441337585, 0.22260636937618256, 0.22261292955875397, 0.22259869611263275, 0.22261390337944031, 0.22261042187213897, 0.22260508949756622, 0.22261437945365906, 0.2226087951183319, 0.222614750623703, 0.22261286256313323, 0.22261211898326874, 0.22260393879413604, 0.2226060614824295, 0.22261173040866852, 0.22260979251861573, 0.22259949045181274, 0.2226040887117386, 0.22260211789608, 0.22260321989059448, 0.22262220017910003, 0.22261444697380067, 0.22261092658042908, 0.22260414242744445, 0.22260652565956116, 0.22259864790439607]}\n",
      "{'MatrixFacto_Adam_MSELoss': [0.3506848581076114, 0.34930455486997963], 'MatrixFacto_Adam_L1Loss': [0.31132066138393666, 0.3390772651674226], 'DN_Adam_MSELoss': [0.08318853439704685, 0.24209600452780725], 'DN_Adam_L1Loss': [0.096676993179035, 0.2275293593287468]}\n"
     ]
    }
   ],
   "source": [
    "print(avg_losses_adam)\n",
    "print(metrics_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MatrixFacto_SGD_MSELoss': [3.9217080088693237, 3.07764855003953], 'MatrixFacto_SGD_L1Loss': [3.86157029292817, 3.0269195351488887], 'DN_SGD_MSELoss': [0.2884027649364175, 0.24198760321438312], 'DN_SGD_L1Loss': [0.310792134475935, 0.22747792307436465]}\n",
      "{'MatrixFacto_Adam_MSELoss': [0.5921865061850121, 0.34930455486997963], 'MatrixFacto_Adam_L1Loss': [0.5579611647632268, 0.3390772651674226], 'DN_Adam_MSELoss': [0.28842422643919297, 0.24209600452780725], 'DN_Adam_L1Loss': [0.31092924143450223, 0.2275293593287468]}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import copy\n",
    "\n",
    "n_epochs = len(avg_losses[\"MatrixFacto_SGD_MSELoss\"])\n",
    "x_s = [i for i in range(n_epochs)]\n",
    "show_plots(avg_losses_adam[\"MatrixFacto_Adam_MSELoss\"], avg_losses_adam[\"DN_Adam_MSELoss\"], x_s, [\"epoch\", \"perte moyenne\", \"La perte moyenne selon l'epoch (Adam, MSELoss)\"])\n",
    "show_plots(avg_losses_adam[\"MatrixFacto_Adam_L1Loss\"], avg_losses_adam[\"DN_Adam_L1Loss\"], x_s, [\"epoch\", \"perte moyenne\", \"La perte moyenne selon l'epoch (Adam, L1Loss)\"])\n",
    "new_metrics = copy.deepcopy(metrics)\n",
    "new_metrics_adam = copy.deepcopy(metrics_adam)\n",
    "for k in new_metrics:\n",
    "    new_metrics[k][0] = math.sqrt(new_metrics[k][0])\n",
    "for k in new_metrics_adam:\n",
    "    new_metrics_adam[k][0] = math.sqrt(new_metrics_adam[k][0])\n",
    "print(new_metrics)\n",
    "print(new_metrics_adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 2.3532679082870485\n",
      "epoch 1 : 2.0285055263519287\n",
      "epoch 2 : 1.7517619049072266\n",
      "epoch 3 : 1.5200186256408692\n",
      "epoch 4 : 1.3282728338241576\n",
      "epoch 5 : 1.1717613259315491\n",
      "epoch 6 : 1.0457688935279845\n",
      "epoch 7 : 0.9451094311714172\n",
      "epoch 8 : 0.8645891944885253\n",
      "epoch 9 : 0.7986183426856994\n",
      "[-0.14054292  0.9662505   1.2822028  ... -3.0927534  -1.4036496\n",
      "  0.47507396]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.569557444524765\n",
      "epoch 1 : 0.28219291002750396\n",
      "epoch 2 : 0.2461203859090805\n",
      "epoch 3 : 0.23944840149879457\n",
      "epoch 4 : 0.23540854053497315\n",
      "epoch 5 : 0.2326290789604187\n",
      "epoch 6 : 0.23054633553028106\n",
      "epoch 7 : 0.22911849999427794\n",
      "epoch 8 : 0.22806983199119568\n",
      "epoch 9 : 0.22721655330657958\n",
      "[[0.7310696 ]\n",
      " [0.719586  ]\n",
      " [0.72988665]\n",
      " ...\n",
      " [0.7367393 ]\n",
      " [0.7305653 ]\n",
      " [0.72841185]]\n",
      "epoch 0 : 3.441813327407837\n",
      "epoch 1 : 3.042049879837036\n",
      "epoch 2 : 2.686246572113037\n",
      "epoch 3 : 2.3719406894683837\n",
      "epoch 4 : 2.0953395797729493\n",
      "epoch 5 : 1.8526949365615846\n",
      "epoch 6 : 1.6414245964050294\n",
      "epoch 7 : 1.4592802415847779\n",
      "epoch 8 : 1.3035843821525575\n",
      "epoch 9 : 1.1717767934799195\n",
      "[-1.7183961  -1.5562508   1.4265442  ...  3.6195183  -0.41510916\n",
      "  3.2179258 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.3633001245498657\n",
      "epoch 1 : 0.2814821140050888\n",
      "epoch 2 : 0.26132967066764834\n",
      "epoch 3 : 0.2497469366312027\n",
      "epoch 4 : 0.24385792944431306\n",
      "epoch 5 : 0.24069628708362578\n",
      "epoch 6 : 0.2385522578239441\n",
      "epoch 7 : 0.23684362587928773\n",
      "epoch 8 : 0.23545848803520203\n",
      "epoch 9 : 0.23426035256385802\n",
      "[[0.65094376]\n",
      " [0.69226366]\n",
      " [0.67615795]\n",
      " ...\n",
      " [0.63618314]\n",
      " [0.69206446]\n",
      " [0.6471809 ]]\n",
      "epoch 0 : 4.117683324432373\n",
      "epoch 1 : 3.6719522567749023\n",
      "epoch 2 : 3.2732829921722413\n",
      "epoch 3 : 2.9183723083496096\n",
      "epoch 4 : 2.602628797149658\n",
      "epoch 5 : 2.3218616603851316\n",
      "epoch 6 : 2.0729869728088377\n",
      "epoch 7 : 1.8526558261871338\n",
      "epoch 8 : 1.6582806777954102\n",
      "epoch 9 : 1.4878270671844482\n",
      "[ 7.814149   -0.57959414 -2.6317832  ... -2.1768312  -4.9825177\n",
      "  1.4294105 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.3068017133712769\n",
      "epoch 1 : 0.2605135987043381\n",
      "epoch 2 : 0.249848513174057\n",
      "epoch 3 : 0.24409445927143097\n",
      "epoch 4 : 0.24066968636512756\n",
      "epoch 5 : 0.2385716139793396\n",
      "epoch 6 : 0.23672765851020813\n",
      "epoch 7 : 0.23537051532268524\n",
      "epoch 8 : 0.23402030448913574\n",
      "epoch 9 : 0.2328760910987854\n",
      "[[0.6778888 ]\n",
      " [0.67105204]\n",
      " [0.67877704]\n",
      " ...\n",
      " [0.6583581 ]\n",
      " [0.7206274 ]\n",
      " [0.6955311 ]]\n",
      "epoch 0 : 2.3171188606262207\n",
      "epoch 1 : 1.996580200958252\n",
      "epoch 2 : 1.7240561010360718\n",
      "epoch 3 : 1.4960168363571167\n",
      "epoch 4 : 1.3078707323074341\n",
      "epoch 5 : 1.1555185695648194\n",
      "epoch 6 : 1.0338142922401428\n",
      "epoch 7 : 0.9376716798782349\n",
      "epoch 8 : 0.8619216427803039\n",
      "epoch 9 : 0.8014102156639099\n",
      "epoch 10 : 0.7519158632278442\n",
      "epoch 11 : 0.7092241046905517\n",
      "epoch 12 : 0.669101374912262\n",
      "epoch 13 : 0.6265896564960479\n",
      "epoch 14 : 0.5763210515975952\n",
      "epoch 15 : 0.5164489581108094\n",
      "epoch 16 : 0.4522381429195404\n",
      "epoch 17 : 0.3933082423686981\n",
      "epoch 18 : 0.3452293432712555\n",
      "epoch 19 : 0.3076096885442734\n",
      "epoch 20 : 0.27842984273433685\n",
      "epoch 21 : 0.25584973270893097\n",
      "epoch 22 : 0.23832117307186126\n",
      "epoch 23 : 0.2245320070028305\n",
      "epoch 24 : 0.2137990003347397\n",
      "epoch 25 : 0.20544882323741911\n",
      "epoch 26 : 0.19883240585327147\n",
      "epoch 27 : 0.19351025218963622\n",
      "epoch 28 : 0.18921365087032319\n",
      "epoch 29 : 0.18559503283500672\n",
      "[0.5635356  0.85386884 0.90235096 ... 0.50944054 0.8219713  0.923213  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.3621209463119507\n",
      "epoch 1 : 0.24949246563911437\n",
      "epoch 2 : 0.2414966248035431\n",
      "epoch 3 : 0.23823806047439575\n",
      "epoch 4 : 0.23607389466762543\n",
      "epoch 5 : 0.2345341665506363\n",
      "epoch 6 : 0.23299673879146576\n",
      "epoch 7 : 0.2317382521867752\n",
      "epoch 8 : 0.23081012024879455\n",
      "epoch 9 : 0.22974628851413728\n",
      "epoch 10 : 0.22889577927589416\n",
      "epoch 11 : 0.22811459670066833\n",
      "epoch 12 : 0.2273823634147644\n",
      "epoch 13 : 0.2267912252664566\n",
      "epoch 14 : 0.22621073639392852\n",
      "epoch 15 : 0.22572194402217866\n",
      "epoch 16 : 0.22522360732555388\n",
      "epoch 17 : 0.2248092371940613\n",
      "epoch 18 : 0.22451218996047972\n",
      "epoch 19 : 0.2242801147222519\n",
      "epoch 20 : 0.2240717039346695\n",
      "epoch 21 : 0.22388209416866303\n",
      "epoch 22 : 0.22367844264507294\n",
      "epoch 23 : 0.22353349001407624\n",
      "epoch 24 : 0.22338847115039825\n",
      "epoch 25 : 0.22333500463962555\n",
      "epoch 26 : 0.22327422025203705\n",
      "epoch 27 : 0.22321294281482695\n",
      "epoch 28 : 0.22316173932552338\n",
      "epoch 29 : 0.22314031841754914\n",
      "[[0.749868  ]\n",
      " [0.74987555]\n",
      " [0.7498745 ]\n",
      " ...\n",
      " [0.74987346]\n",
      " [0.7498784 ]\n",
      " [0.7498686 ]]\n",
      "epoch 0 : 3.3978795196533205\n",
      "epoch 1 : 2.9992780342102052\n",
      "epoch 2 : 2.6452824836730957\n",
      "epoch 3 : 2.3329853897094726\n",
      "epoch 4 : 2.058795886993408\n",
      "epoch 5 : 1.8189743524551392\n",
      "epoch 6 : 1.6112236909866333\n",
      "epoch 7 : 1.4319211767196656\n",
      "epoch 8 : 1.2788778794288636\n",
      "epoch 9 : 1.1491722601890564\n",
      "epoch 10 : 1.0396047574996947\n",
      "epoch 11 : 0.9471164120674134\n",
      "epoch 12 : 0.8686977251052856\n",
      "epoch 13 : 0.7998897785186767\n",
      "epoch 14 : 0.7376397062301636\n",
      "epoch 15 : 0.6789236314296723\n",
      "epoch 16 : 0.6212858810901641\n",
      "epoch 17 : 0.5639227437019348\n",
      "epoch 18 : 0.5080902359008789\n",
      "epoch 19 : 0.4562168974399567\n",
      "epoch 20 : 0.4099878188610077\n",
      "epoch 21 : 0.37054892106056214\n",
      "epoch 22 : 0.3371576451539993\n",
      "epoch 23 : 0.30931966755390167\n",
      "epoch 24 : 0.2860131521940231\n",
      "epoch 25 : 0.2666794331789017\n",
      "epoch 26 : 0.2503846672296524\n",
      "epoch 27 : 0.23670325286388397\n",
      "epoch 28 : 0.22509049751758575\n",
      "epoch 29 : 0.2153811148405075\n",
      "[-0.02410591 -1.5486847   1.0377332  ...  1.0011398   0.67110884\n",
      "  1.967653  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.3619090999364853\n",
      "epoch 1 : 0.25458299663066863\n",
      "epoch 2 : 0.24547721855640411\n",
      "epoch 3 : 0.2413262476682663\n",
      "epoch 4 : 0.23877528619766236\n",
      "epoch 5 : 0.2367586140871048\n",
      "epoch 6 : 0.23495430171489715\n",
      "epoch 7 : 0.23347095587253572\n",
      "epoch 8 : 0.23219103367328645\n",
      "epoch 9 : 0.2309188988685608\n",
      "epoch 10 : 0.22972137362957\n",
      "epoch 11 : 0.22867506003379823\n",
      "epoch 12 : 0.22772456593513488\n",
      "epoch 13 : 0.22685188121795655\n",
      "epoch 14 : 0.22612397108078003\n",
      "epoch 15 : 0.22543584632873534\n",
      "epoch 16 : 0.22485332205295563\n",
      "epoch 17 : 0.22436471266746522\n",
      "epoch 18 : 0.22402769947052\n",
      "epoch 19 : 0.22386088156700135\n",
      "epoch 20 : 0.22371747975349426\n",
      "epoch 21 : 0.22358711476325988\n",
      "epoch 22 : 0.22345738048553468\n",
      "epoch 23 : 0.22339576570987701\n",
      "epoch 24 : 0.22332051033973693\n",
      "epoch 25 : 0.22324468157291413\n",
      "epoch 26 : 0.22318178298473357\n",
      "epoch 27 : 0.22312647173404693\n",
      "epoch 28 : 0.22308048450946807\n",
      "epoch 29 : 0.22304695284366607\n",
      "[[0.74965334]\n",
      " [0.7496481 ]\n",
      " [0.7496218 ]\n",
      " ...\n",
      " [0.74969894]\n",
      " [0.74968284]\n",
      " [0.7496786 ]]\n",
      "epoch 0 : 4.19613159866333\n",
      "epoch 1 : 3.7465336475372313\n",
      "epoch 2 : 3.34290842628479\n",
      "epoch 3 : 2.9823086601257325\n",
      "epoch 4 : 2.660487463188171\n",
      "epoch 5 : 2.3745408863067627\n",
      "epoch 6 : 2.120480744552612\n",
      "epoch 7 : 1.8958007860183717\n",
      "epoch 8 : 1.6979594751358031\n",
      "epoch 9 : 1.5241356164932252\n",
      "epoch 10 : 1.3721185920715333\n",
      "epoch 11 : 1.2410262619018555\n",
      "epoch 12 : 1.1273099571228027\n",
      "epoch 13 : 1.0288904408454895\n",
      "epoch 14 : 0.9435166566848755\n",
      "epoch 15 : 0.8690196000099182\n",
      "epoch 16 : 0.8032925886154175\n",
      "epoch 17 : 0.7438033712387085\n",
      "epoch 18 : 0.688742340707779\n",
      "epoch 19 : 0.6374422739505767\n",
      "epoch 20 : 0.5876227243900299\n",
      "epoch 21 : 0.5414004583835602\n",
      "epoch 22 : 0.49704349565505984\n",
      "epoch 23 : 0.45572950196266176\n",
      "epoch 24 : 0.41800001759529115\n",
      "epoch 25 : 0.3841281394004822\n",
      "epoch 26 : 0.35404445452690125\n",
      "epoch 27 : 0.32754699618816374\n",
      "epoch 28 : 0.30479017877578735\n",
      "epoch 29 : 0.2851603111028671\n",
      "[-1.6628596  -1.0383699   0.64560807 ... -1.8581467   0.49528837\n",
      " -0.21736205]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.30041157240867616\n",
      "epoch 1 : 0.2628925848722458\n",
      "epoch 2 : 0.252678075838089\n",
      "epoch 3 : 0.24656692266464234\n",
      "epoch 4 : 0.24292338857650758\n",
      "epoch 5 : 0.2406995166540146\n",
      "epoch 6 : 0.2391055216550827\n",
      "epoch 7 : 0.23781554291248322\n",
      "epoch 8 : 0.23668727166652678\n",
      "epoch 9 : 0.235629105591774\n",
      "epoch 10 : 0.23463851232528687\n",
      "epoch 11 : 0.23377573120594025\n",
      "epoch 12 : 0.2328697205066681\n",
      "epoch 13 : 0.23197945816516877\n",
      "epoch 14 : 0.23123099451065063\n",
      "epoch 15 : 0.2304493021249771\n",
      "epoch 16 : 0.22970729365348816\n",
      "epoch 17 : 0.22901645271778107\n",
      "epoch 18 : 0.22842870552539826\n",
      "epoch 19 : 0.2278050922393799\n",
      "epoch 20 : 0.22724637649059296\n",
      "epoch 21 : 0.22668149406909943\n",
      "epoch 22 : 0.22616570799350738\n",
      "epoch 23 : 0.22571072041988371\n",
      "epoch 24 : 0.22528725428581237\n",
      "epoch 25 : 0.22490594565868377\n",
      "epoch 26 : 0.22454851179122925\n",
      "epoch 27 : 0.2242684559583664\n",
      "epoch 28 : 0.2240007699251175\n",
      "epoch 29 : 0.22377827413082121\n",
      "[[0.75386125]\n",
      " [0.75101006]\n",
      " [0.7462717 ]\n",
      " ...\n",
      " [0.7446215 ]\n",
      " [0.74652076]\n",
      " [0.7475557 ]]\n",
      "epoch 0 : 2.3184837926864623\n",
      "epoch 1 : 1.9966167695999146\n",
      "epoch 2 : 1.7227442222595215\n",
      "epoch 3 : 1.4929744398117066\n",
      "epoch 4 : 1.303446916770935\n",
      "epoch 5 : 1.1495491835594178\n",
      "epoch 6 : 1.026063136959076\n",
      "epoch 7 : 0.927946031665802\n",
      "epoch 8 : 0.8491936369895935\n",
      "epoch 9 : 0.7836776846885681\n",
      "epoch 10 : 0.7261875690460206\n",
      "epoch 11 : 0.671173284816742\n",
      "epoch 12 : 0.6129804945945739\n",
      "epoch 13 : 0.5488613771438599\n",
      "epoch 14 : 0.48202795424461364\n",
      "epoch 15 : 0.4195453659057617\n",
      "epoch 16 : 0.3668286959648132\n",
      "epoch 17 : 0.3244514872550964\n",
      "epoch 18 : 0.29135577702522275\n",
      "epoch 19 : 0.26573829143047334\n",
      "epoch 20 : 0.24608106875419616\n",
      "epoch 21 : 0.2307244306087494\n",
      "epoch 22 : 0.21913368899822236\n",
      "epoch 23 : 0.2098855696439743\n",
      "epoch 24 : 0.20249853360652922\n",
      "epoch 25 : 0.19654695799350738\n",
      "epoch 26 : 0.1917061277627945\n",
      "epoch 27 : 0.1876480476140976\n",
      "epoch 28 : 0.18428665220737458\n",
      "epoch 29 : 0.18141089994907378\n",
      "epoch 30 : 0.17893088943958282\n",
      "epoch 31 : 0.1767891950368881\n",
      "epoch 32 : 0.1749348690032959\n",
      "epoch 33 : 0.1733272121667862\n",
      "epoch 34 : 0.1719707919359207\n",
      "epoch 35 : 0.17059715225696565\n",
      "epoch 36 : 0.16953317632675172\n",
      "epoch 37 : 0.16848595843315126\n",
      "epoch 38 : 0.16749184527397157\n",
      "epoch 39 : 0.16669058187007904\n",
      "epoch 40 : 0.16584955122470857\n",
      "epoch 41 : 0.1651256401538849\n",
      "epoch 42 : 0.16449654190540314\n",
      "epoch 43 : 0.1637361207485199\n",
      "epoch 44 : 0.1631686357021332\n",
      "epoch 45 : 0.16262674674987793\n",
      "epoch 46 : 0.16205382931232454\n",
      "epoch 47 : 0.1614679946422577\n",
      "epoch 48 : 0.16109152944087982\n",
      "epoch 49 : 0.16053788826465606\n",
      "[0.81271946 0.8914749  0.9209447  ... 0.47054902 0.5768851  0.5237951 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.5234305478572846\n",
      "epoch 1 : 0.3108505819320679\n",
      "epoch 2 : 0.2651412622690201\n",
      "epoch 3 : 0.24816988940238952\n",
      "epoch 4 : 0.24212219665050508\n",
      "epoch 5 : 0.2386068614244461\n",
      "epoch 6 : 0.23584922692775726\n",
      "epoch 7 : 0.23346553134918213\n",
      "epoch 8 : 0.23155908546447754\n",
      "epoch 9 : 0.22973588075637819\n",
      "epoch 10 : 0.22820895993709564\n",
      "epoch 11 : 0.22693933651447296\n",
      "epoch 12 : 0.2260749184846878\n",
      "epoch 13 : 0.2256770301103592\n",
      "epoch 14 : 0.22527811422348024\n",
      "epoch 15 : 0.2249652181863785\n",
      "epoch 16 : 0.224721457529068\n",
      "epoch 17 : 0.22450175647735596\n",
      "epoch 18 : 0.22428328392505645\n",
      "epoch 19 : 0.22416382648944855\n",
      "epoch 20 : 0.22399185376167297\n",
      "epoch 21 : 0.22384294948577882\n",
      "epoch 22 : 0.2237189736843109\n",
      "epoch 23 : 0.2236430183172226\n",
      "epoch 24 : 0.2235556892156601\n",
      "epoch 25 : 0.22349612488746642\n",
      "epoch 26 : 0.22342220118045808\n",
      "epoch 27 : 0.22337714376449586\n",
      "epoch 28 : 0.22332242691516876\n",
      "epoch 29 : 0.22326947574615477\n",
      "epoch 30 : 0.22324174258708954\n",
      "epoch 31 : 0.22314740574359893\n",
      "epoch 32 : 0.22313749730587007\n",
      "epoch 33 : 0.22309436311721803\n",
      "epoch 34 : 0.22303579745292665\n",
      "epoch 35 : 0.22300467734336854\n",
      "epoch 36 : 0.2229754051685333\n",
      "epoch 37 : 0.22295634803771971\n",
      "epoch 38 : 0.2229360229253769\n",
      "epoch 39 : 0.22292079119682312\n",
      "epoch 40 : 0.22289533343315124\n",
      "epoch 41 : 0.22288459486961365\n",
      "epoch 42 : 0.22286917576789855\n",
      "epoch 43 : 0.22285216808319092\n",
      "epoch 44 : 0.22282604598999023\n",
      "epoch 45 : 0.222811870265007\n",
      "epoch 46 : 0.2228066962003708\n",
      "epoch 47 : 0.22278916642665864\n",
      "epoch 48 : 0.22277478511333465\n",
      "epoch 49 : 0.22276603894233704\n",
      "[[0.7494688 ]\n",
      " [0.74947786]\n",
      " [0.74940723]\n",
      " ...\n",
      " [0.74942714]\n",
      " [0.74947345]\n",
      " [0.74950856]]\n",
      "epoch 0 : 3.402394815826416\n",
      "epoch 1 : 3.00328064994812\n",
      "epoch 2 : 2.649406145095825\n",
      "epoch 3 : 2.3371121271133424\n",
      "epoch 4 : 2.0621875339508056\n",
      "epoch 5 : 1.8212693380355836\n",
      "epoch 6 : 1.611569436264038\n",
      "epoch 7 : 1.4308147497177124\n",
      "epoch 8 : 1.2766650859832764\n",
      "epoch 9 : 1.1461364544868469\n",
      "epoch 10 : 1.0357781279563905\n",
      "epoch 11 : 0.9427279731750489\n",
      "epoch 12 : 0.8630923625946045\n",
      "epoch 13 : 0.794207266998291\n",
      "epoch 14 : 0.732133731842041\n",
      "epoch 15 : 0.6736755860328675\n",
      "epoch 16 : 0.6169931368350983\n",
      "epoch 17 : 0.5613155505180359\n",
      "epoch 18 : 0.5072191837787628\n",
      "epoch 19 : 0.45672398142814635\n",
      "epoch 20 : 0.411810925245285\n",
      "epoch 21 : 0.37259587173461917\n",
      "epoch 22 : 0.33914992768764496\n",
      "epoch 23 : 0.310919446182251\n",
      "epoch 24 : 0.28722919516563417\n",
      "epoch 25 : 0.2676449854850769\n",
      "epoch 26 : 0.25073381018638613\n",
      "epoch 27 : 0.23700573394298555\n",
      "epoch 28 : 0.22558908588886262\n",
      "epoch 29 : 0.21577981193065643\n",
      "epoch 30 : 0.20738092687129975\n",
      "epoch 31 : 0.20030961158275604\n",
      "epoch 32 : 0.1946055076599121\n",
      "epoch 33 : 0.18929342629909515\n",
      "epoch 34 : 0.18481745779514314\n",
      "epoch 35 : 0.18090067377090455\n",
      "epoch 36 : 0.17736150255203248\n",
      "epoch 37 : 0.1743921692609787\n",
      "epoch 38 : 0.1715989917755127\n",
      "epoch 39 : 0.16910980229377748\n",
      "epoch 40 : 0.16705125211477279\n",
      "epoch 41 : 0.16501957092285155\n",
      "epoch 42 : 0.16313448271751405\n",
      "epoch 43 : 0.1616759841322899\n",
      "epoch 44 : 0.1601390873193741\n",
      "epoch 45 : 0.1587348245382309\n",
      "epoch 46 : 0.1574816889643669\n",
      "epoch 47 : 0.1563315567612648\n",
      "epoch 48 : 0.1552222650527954\n",
      "epoch 49 : 0.15416859154701232\n",
      "[-0.36375037  1.3269491   1.0247939  ...  1.713816    0.38436496\n",
      "  0.16077936]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.486606840467453\n",
      "epoch 1 : 0.30041748275756835\n",
      "epoch 2 : 0.26754584965705874\n",
      "epoch 3 : 0.2518197122335434\n",
      "epoch 4 : 0.2443888658285141\n",
      "epoch 5 : 0.2406908292531967\n",
      "epoch 6 : 0.23827873072624206\n",
      "epoch 7 : 0.23627509799003601\n",
      "epoch 8 : 0.23474010801315306\n",
      "epoch 9 : 0.23317079780101777\n",
      "epoch 10 : 0.231901544880867\n",
      "epoch 11 : 0.2306211946964264\n",
      "epoch 12 : 0.22942501187324524\n",
      "epoch 13 : 0.22837121407985686\n",
      "epoch 14 : 0.22741778135299684\n",
      "epoch 15 : 0.22657495718002318\n",
      "epoch 16 : 0.22593422224521637\n",
      "epoch 17 : 0.22533531682491303\n",
      "epoch 18 : 0.22484543421268463\n",
      "epoch 19 : 0.22444321274757384\n",
      "epoch 20 : 0.22413818747997283\n",
      "epoch 21 : 0.22396452119350432\n",
      "epoch 22 : 0.22377972555160522\n",
      "epoch 23 : 0.22366798095703125\n",
      "epoch 24 : 0.2235560433626175\n",
      "epoch 25 : 0.22350212938785552\n",
      "epoch 26 : 0.2234506241083145\n",
      "epoch 27 : 0.22340496752262115\n",
      "epoch 28 : 0.2233363292694092\n",
      "epoch 29 : 0.223302161693573\n",
      "epoch 30 : 0.22324808101654053\n",
      "epoch 31 : 0.2232028689146042\n",
      "epoch 32 : 0.2231584048986435\n",
      "epoch 33 : 0.2231148086309433\n",
      "epoch 34 : 0.22306834573745726\n",
      "epoch 35 : 0.22304770555496214\n",
      "epoch 36 : 0.22300681295394897\n",
      "epoch 37 : 0.2229762934923172\n",
      "epoch 38 : 0.22295025291442871\n",
      "epoch 39 : 0.2229220141172409\n",
      "epoch 40 : 0.22289757385253905\n",
      "epoch 41 : 0.2228839212656021\n",
      "epoch 42 : 0.2228702342748642\n",
      "epoch 43 : 0.2228587459564209\n",
      "epoch 44 : 0.2228638504743576\n",
      "epoch 45 : 0.22285411865711213\n",
      "epoch 46 : 0.22285066010951995\n",
      "epoch 47 : 0.22284857258796692\n",
      "epoch 48 : 0.22284430632591248\n",
      "epoch 49 : 0.22284237661361694\n",
      "[[0.74990344]\n",
      " [0.7499244 ]\n",
      " [0.74991864]\n",
      " ...\n",
      " [0.74989754]\n",
      " [0.74990624]\n",
      " [0.74992657]]\n",
      "epoch 0 : 4.292303910064697\n",
      "epoch 1 : 3.8357203300476073\n",
      "epoch 2 : 3.4262149993896482\n",
      "epoch 3 : 3.0608542068481444\n",
      "epoch 4 : 2.7343378101348876\n",
      "epoch 5 : 2.4436248334884643\n",
      "epoch 6 : 2.1851882049560545\n",
      "epoch 7 : 1.9551629364013672\n",
      "epoch 8 : 1.7516783222198486\n",
      "epoch 9 : 1.5732525270462037\n",
      "epoch 10 : 1.4166224817276\n",
      "epoch 11 : 1.2806241659164428\n",
      "epoch 12 : 1.1626166728973388\n",
      "epoch 13 : 1.0603352234840393\n",
      "epoch 14 : 0.9713502022743226\n",
      "epoch 15 : 0.8936716669082642\n",
      "epoch 16 : 0.8244779559135437\n",
      "epoch 17 : 0.762437831401825\n",
      "epoch 18 : 0.7052561420440674\n",
      "epoch 19 : 0.6511793157577515\n",
      "epoch 20 : 0.6004490035533905\n",
      "epoch 21 : 0.5515891891479492\n",
      "epoch 22 : 0.5058352692127228\n",
      "epoch 23 : 0.46317907304763795\n",
      "epoch 24 : 0.4243250633239746\n",
      "epoch 25 : 0.38975048098564147\n",
      "epoch 26 : 0.35905061621665957\n",
      "epoch 27 : 0.33249581770896913\n",
      "epoch 28 : 0.30906063470840456\n",
      "epoch 29 : 0.2887432285785675\n",
      "epoch 30 : 0.2713969347000122\n",
      "epoch 31 : 0.25632879605293274\n",
      "epoch 32 : 0.24332584040164948\n",
      "epoch 33 : 0.23202801587581634\n",
      "epoch 34 : 0.2219251715183258\n",
      "epoch 35 : 0.2136081475496292\n",
      "epoch 36 : 0.20613668010234834\n",
      "epoch 37 : 0.19941412448883056\n",
      "epoch 38 : 0.1937324408531189\n",
      "epoch 39 : 0.18843929302692414\n",
      "epoch 40 : 0.18378059871196747\n",
      "epoch 41 : 0.1796109086036682\n",
      "epoch 42 : 0.17630058716535568\n",
      "epoch 43 : 0.17257312639951705\n",
      "epoch 44 : 0.1697121098279953\n",
      "epoch 45 : 0.1669495788216591\n",
      "epoch 46 : 0.16449099029302597\n",
      "epoch 47 : 0.1624400127530098\n",
      "epoch 48 : 0.16021664814949035\n",
      "epoch 49 : 0.1584136683821678\n",
      "[-0.11616158  0.993579    0.88988847 ... -0.06904894 -0.14064592\n",
      " -0.7302648 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajsa\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:88: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 0.4312871654033661\n",
      "epoch 1 : 0.26535090916156767\n",
      "epoch 2 : 0.2527810113430023\n",
      "epoch 3 : 0.2464243978738785\n",
      "epoch 4 : 0.24258900809288025\n",
      "epoch 5 : 0.24011814427375794\n",
      "epoch 6 : 0.2383154060125351\n",
      "epoch 7 : 0.23682705092430115\n",
      "epoch 8 : 0.23559083983898163\n",
      "epoch 9 : 0.2344885615348816\n",
      "epoch 10 : 0.23338642444610597\n",
      "epoch 11 : 0.23236875095367432\n",
      "epoch 12 : 0.23144996745586396\n",
      "epoch 13 : 0.23061561188697816\n",
      "epoch 14 : 0.2298503945350647\n",
      "epoch 15 : 0.2290913472175598\n",
      "epoch 16 : 0.22831414966583252\n",
      "epoch 17 : 0.22762349228858947\n",
      "epoch 18 : 0.22697973160743715\n",
      "epoch 19 : 0.22646531298160552\n",
      "epoch 20 : 0.22593739488124848\n",
      "epoch 21 : 0.22546668610572815\n",
      "epoch 22 : 0.2250663186073303\n",
      "epoch 23 : 0.22471660978794097\n",
      "epoch 24 : 0.22444293599128723\n",
      "epoch 25 : 0.22420388963222504\n",
      "epoch 26 : 0.22402165944576263\n",
      "epoch 27 : 0.22388658213615417\n",
      "epoch 28 : 0.22378155286312104\n",
      "epoch 29 : 0.22366274371147155\n",
      "epoch 30 : 0.22354384891986848\n",
      "epoch 31 : 0.22346290805339813\n",
      "epoch 32 : 0.22335286059379578\n",
      "epoch 33 : 0.22327096614837647\n",
      "epoch 34 : 0.22318942914009093\n",
      "epoch 35 : 0.22312083089351653\n",
      "epoch 36 : 0.22306185755729677\n",
      "epoch 37 : 0.22299776628017426\n",
      "epoch 38 : 0.22293893358707428\n",
      "epoch 39 : 0.22289490847587584\n",
      "epoch 40 : 0.22286658799648285\n",
      "epoch 41 : 0.22284295089244843\n",
      "epoch 42 : 0.222810249710083\n",
      "epoch 43 : 0.22279483976364137\n",
      "epoch 44 : 0.2227788782596588\n",
      "epoch 45 : 0.22276620030403138\n",
      "epoch 46 : 0.22275841748714448\n",
      "epoch 47 : 0.22273857612609863\n",
      "epoch 48 : 0.2227328096151352\n",
      "epoch 49 : 0.22272409720420838\n",
      "[[0.74957764]\n",
      " [0.749558  ]\n",
      " [0.7495662 ]\n",
      " ...\n",
      " [0.7495863 ]\n",
      " [0.7495303 ]\n",
      " [0.7495802 ]]\n"
     ]
    }
   ],
   "source": [
    "from time import process_time\n",
    "\n",
    "n_factors = [10, 20, 30]\n",
    "loss_func = nn.L1Loss()\n",
    "batch_size = 128\n",
    "\n",
    "n_epochs = [10, 30, 50]\n",
    "times = {}\n",
    "metrics_e_l = {}\n",
    "for e in n_epochs:\n",
    "    for f in n_factors:\n",
    "        model_mf = MatrixFacto(n_users, n_items, f)\n",
    "        model_mf.cuda()\n",
    "        optimizer_mf = Adam(model_mf.parameters(), lr=0.001)\n",
    "        t1 = process_time()\n",
    "        avg_losses_mf, _ = train(e, train_data, batch_size, optimizer_mf, loss_func, model_mf)\n",
    "        times[\"MF_Adam_L1\" + str(e) + \"_\" + str(f)] = process_time() - t1\n",
    "        test_pred_mf = evaluate(model_mf, test_data)\n",
    "        metrics_e_l[\"MF_Adam_L1\" + str(e) + \"_\" + str(f)] = [math.sqrt(mean_squared_error(test_pred_mf.cpu().numpy(), test_data[\"rating\"].values)), \n",
    "                   mean_absolute_error(test_pred_mf.cpu().numpy(), test_data[\"rating\"].values)]\n",
    "        \n",
    "        model_dn = DN(n_users, n_items, f)\n",
    "        model_dn.cuda()\n",
    "        optimizer_dn = SGD(model_dn.parameters(), lr=0.001)\n",
    "        t1 = process_time()\n",
    "        avg_losses_dn, _ = train(e, train_data, batch_size, optimizer_dn, loss_func, model_dn)\n",
    "        times[\"DN_SGD_L1\" + str(e) + \"_\" + str(f)] = process_time() - t1\n",
    "        test_pred_dn = evaluate(model_dn, test_data)\n",
    "        metrics_e_l[\"DN_SGD_L1\" + str(e) + \"_\" + str(f)] = [math.sqrt(mean_squared_error(test_pred_dn.cpu().numpy(), test_data[\"rating\"].values)), \n",
    "                   mean_absolute_error(test_pred_dn.cpu().numpy(), test_data[\"rating\"].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MF_Adam_L110_10': [1.2465441630132725, 0.9508738031747751], 'DN_SGD_L110_10': [0.30475144009760824, 0.2296769399702549], 'MF_Adam_L110_20': [2.0267923894721864, 1.5333809041680768], 'DN_SGD_L110_20': [0.29009132306781477, 0.23746891760528088], 'MF_Adam_L110_30': [2.8320354743149183, 2.1531438987959177], 'DN_SGD_L110_30': [0.29244658198698587, 0.2367205414891243], 'MF_Adam_L130_10': [0.4254574226668644, 0.2742562234473269], 'DN_SGD_L130_10': [0.3106858106640016, 0.2275124241858721], 'MF_Adam_L130_20': [0.8145842925685409, 0.4886871631555783], 'DN_SGD_L130_20': [0.3107575533154649, 0.22751151804327965], 'MF_Adam_L130_30': [1.3086796450348666, 0.8312914019875578], 'DN_SGD_L130_30': [0.30980112841944657, 0.22790857069790363], 'MF_Adam_L150_10': [0.3904453616984802, 0.2510979905397748], 'DN_SGD_L150_10': [0.3106456511196849, 0.2275249383598566], 'MF_Adam_L150_20': [0.6371302819110117, 0.3673823411445599], 'DN_SGD_L150_20': [0.3108158512917604, 0.227496409034729], 'MF_Adam_L150_30': [1.005410069282126, 0.5739772296504351], 'DN_SGD_L150_30': [0.3106761665319142, 0.22751050332784653]}\n",
      "{'MF_Adam_L110_10': 16.421875, 'DN_SGD_L110_10': 23.03125, 'MF_Adam_L110_20': 16.5, 'DN_SGD_L110_20': 23.140625, 'MF_Adam_L110_30': 16.453125, 'DN_SGD_L110_30': 23.21875, 'MF_Adam_L130_10': 49.25, 'DN_SGD_L130_10': 69.109375, 'MF_Adam_L130_20': 49.515625, 'DN_SGD_L130_20': 68.265625, 'MF_Adam_L130_30': 49.9375, 'DN_SGD_L130_30': 69.046875, 'MF_Adam_L150_10': 83.28125, 'DN_SGD_L150_10': 115.46875, 'MF_Adam_L150_20': 83.671875, 'DN_SGD_L150_20': 114.984375, 'MF_Adam_L150_30': 83.375, 'DN_SGD_L150_30': 115.109375}\n"
     ]
    }
   ],
   "source": [
    "print(metrics_e_l)\n",
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
